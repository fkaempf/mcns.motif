{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7798ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import graph_tool.all as gt\n",
    "from motif_counts import *\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import pickle\n",
    "#from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7266827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('mcns_fw_edge_comp.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99fb8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) build a unique list of all node labels\n",
    "labels = np.unique(np.concatenate([df['pre'].values, df['post'].values]))\n",
    "\n",
    "# 2) create the graph and a string vertex‐property to store the label\n",
    "g = gt.Graph(directed=True)\n",
    "v_label = g.new_vp(\"string\")\n",
    "g.vp[\"label\"] = v_label\n",
    "\n",
    "# 3) add one vertex per label, keep a Python dict to map label→vertex\n",
    "label2v = {}\n",
    "for L in labels:\n",
    "    v = g.add_vertex()\n",
    "    label2v[L] = v\n",
    "    v_label[v] = str(L)\n",
    "\n",
    "# 4) create a float edge‐property for your weights\n",
    "e_weight = g.new_ep(\"float\")\n",
    "g.ep[\"weight\"] = e_weight\n",
    "\n",
    "# 5) add all edges with their weights\n",
    "edge_list = [\n",
    "    (label2v[src], label2v[tgt], float(w))\n",
    "    for src, tgt, w in df[['pre','post','weight_m']].itertuples(index=False)\n",
    "]\n",
    "g.add_edge_list(edge_list, eprops=[g.ep[\"weight\"]])\n",
    "loops = [e for e in g.edges() if e.source() == e.target()]\n",
    "for e in loops:\n",
    "    g.remove_edge(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3295568",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = list(range(g.num_vertices()))\n",
    "E = {\n",
    "    (int(e.source()), int(e.target()))\n",
    "    for e in g.edges()\n",
    "    if g.ep['weight'][e] >= 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5839a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████████████████████████▉                                                                                                                                                                                         | 143867/863843 [12:43<37:59:59,  5.26it/s]IOStream.flush timed out\n",
      " 26%|██████████████████████████████████████████████████████████▎                                                                                                                                                                     | 224816/863843 [18:32<39:04, 272.52it/s]IOStream.flush timed out\n",
      " 41%|██████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                     | 350597/863843 [29:35<34:00, 251.54it/s]"
     ]
    }
   ],
   "source": [
    "def _process_edge(a, b, nbr_out, nbr_in, Eset):\n",
    "    local = set()\n",
    "    # only c’s that could possibly add any extra edge\n",
    "    candidates = (nbr_out[a] | nbr_in[a] | nbr_out[b] | nbr_in[b]) - {a, b}\n",
    "\n",
    "    for c in candidates:\n",
    "        t = Triplet([a, b, c])\n",
    "        t.add_edge(a, b)\n",
    "        # check the other five directed edges\n",
    "        for src, dst in ((a, c), (c, a), (b, c), (c, b), (b, a)):\n",
    "            if (src, dst) in Eset:\n",
    "                t.add_edge(src, dst)\n",
    "        local.add(t)\n",
    "\n",
    "    return local\n",
    "\n",
    "def collect_triplets_parallel(E, V, n_jobs=-1, prefer=\"threads\"):\n",
    "    # ensure O(1) lookups\n",
    "    Eset = set(E)\n",
    "\n",
    "    # build directed adjacency once\n",
    "    nbr_out = defaultdict(set)\n",
    "    nbr_in  = defaultdict(set)\n",
    "    for u, v in Eset:\n",
    "        nbr_out[u].add(v)\n",
    "        nbr_in[v].add(u)\n",
    "\n",
    "    # parallel map over edges\n",
    "    results = Parallel(n_jobs=n_jobs, prefer=prefer)(\n",
    "        delayed(_process_edge)(a, b, nbr_out, nbr_in, Eset)\n",
    "        for a, b in tqdm(Eset, total=len(Eset))\n",
    "    )\n",
    "\n",
    "    # union all the per-edge sets\n",
    "    tri = set().union(*results)\n",
    "    return tri\n",
    "\n",
    "\n",
    "tri = collect_triplets_parallel(E, V)\n",
    "#with open('tri.pkl', 'wb') as f:\n",
    "    # protocol=pickle.HIGHEST_PROTOCOL uses the most efficient format\n",
    "    #pickle.dump(tri, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6700acc-9d57-49d6-879c-564067a2946c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 μs, sys: 0 ns, total: 2 μs\n",
      "Wall time: 3.34 μs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "with open('tri.pkl', 'rb') as f:\n",
    "    tri = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5346d6bb-c421-4092-b813-3778421b9403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 168543875/168543875 [22:02<00:00, 127461.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# grab the iterable of Triplet objects\n",
    "triplet_iter = iter(tri)\n",
    "\n",
    "# build a list of plain dicts, one per triplet\n",
    "rows = []\n",
    "for t in tqdm(triplet_iter,total=len(tri)):\n",
    "    # t.vertices maps local‐indices 0,1,2 → original node IDs\n",
    "    v = t.vertices\n",
    "    rows.append({\n",
    "        'node0': v[0],\n",
    "        'node1': v[1],\n",
    "        'node2': v[2],\n",
    "        # store edges as a list of tuples\n",
    "        'edges': list(t.edges),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame.from_records(rows)\n",
    "df.to_feather(\"motifcounts_triplets.feather\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
